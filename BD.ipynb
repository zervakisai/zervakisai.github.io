{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqrmayGkoKx-"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Παίρνουμε το full dataset σε streaming mode\n",
        "dataset = load_dataset(\"bookcorpus\", split=\"train\", streaming=True)"
      ],
      "metadata": {
        "id": "qEfhl6XdoOKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"bookcorpus.csv\"\n",
        "\n",
        "# Δημιουργία αρχείου με header\n",
        "with open(csv_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"text\\n\")\n",
        "\n",
        "# Batch export\n",
        "batch_size = 200_000\n",
        "batch = []\n",
        "total = 0\n",
        "\n",
        "for i, example in enumerate(dataset):\n",
        "    batch.append(example)\n",
        "    if (i + 1) % batch_size == 0:\n",
        "        df = pd.DataFrame(batch)\n",
        "        df.to_csv(csv_path, mode='a', header=False, index=False)\n",
        "        total += len(batch)\n",
        "        print(f\"✅ Saved {total:,} rows...\")\n",
        "        batch = []\n",
        "\n",
        "# Αποθήκευση τελευταίου batch\n",
        "if batch:\n",
        "    df = pd.DataFrame(batch)\n",
        "    df.to_csv(csv_path, mode='a', header=False, index=False)\n",
        "    total += len(batch)\n",
        "    print(f\"✅ Final batch saved (total: {total:,})\")\n"
      ],
      "metadata": {
        "id": "DzqD22tDoQgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-11-jdk -y\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar -xvzf spark-3.4.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BookCorpusAnalysis\") \\\n",
        "    .config(\"spark.ui.port\", \"4040\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "M9aC0eBboTcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, split, size\n",
        "\n",
        "# Στήλη με αριθμό λέξεων\n",
        "df_words = df.withColumn(\"word_count\", size(split(col(\"text\"), \"\\\\s+\")))\n",
        "\n",
        "# Στατιστικά word counts\n",
        "df_words.select(\"word_count\").summary(\"count\", \"mean\", \"min\", \"25%\", \"50%\", \"75%\", \"max\").show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8tQohsheoXM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok για Spark UI\n",
        "!wget -q -nc https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-stable-linux-amd64.zip\n",
        "!unzip -n ngrok-stable-linux-amd64.zip\n",
        "# Ορισμός του Ngrok token\n",
        "!./ngrok authtoken 2uzOrSfKyZmx3KsoUMO8UpSYJ5x_3yfwivzhuBKEVTJJjJncJ\n",
        "# Ξεκινάμε το ngrok tunnel προς την πόρτα του Spark UI\n",
        "get_ipython().system_raw('./ngrok http 4040 --log=stdout > ngrok.log &')"
      ],
      "metadata": {
        "id": "EWEsEMulohQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time, requests\n",
        "time.sleep(3)\n",
        "\n",
        "try:\n",
        "    r = requests.get('http://localhost:4040/api/tunnels')\n",
        "    ui_url = r.json()['tunnels'][0]['public_url']\n",
        "    print(f\"🚀 Spark UI is live at: {ui_url}\")\n",
        "except:\n",
        "    print(\"❌ Ngrok δεν συνδέθηκε\")\n",
        "    !tail -n 20 ngrok.log\n",
        "\n"
      ],
      "metadata": {
        "id": "YJgbAFdRojIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, lower, regexp_replace, split, col, length\n",
        "\n",
        "# Καθαρισμός κειμένου + Tokenization + Explode\n",
        "df_tokens = df.select(\"text\").na.drop().repartition(8).select(\n",
        "    explode(\n",
        "        split(\n",
        "            lower(\n",
        "                regexp_replace(col(\"text\"), r\"[^a-zA-Z]\", \" \")\n",
        "            ),\n",
        "            r\"\\s+\"\n",
        "        )\n",
        "    ).alias(\"word\")\n",
        ").filter(length(col(\"word\")) > 2)  # αγνόηση μικρών λέξεων"
      ],
      "metadata": {
        "id": "jV9AG_beooxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ομαδοποίηση και μέτρηση συχνοτήτων\n",
        "word_freq = df_tokens.groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
        "\n",
        "# Προβολή top-20 (Spark UI δείχνει το stage)\n",
        "word_freq.show(20, truncate=False)"
      ],
      "metadata": {
        "id": "HhSMdnQQorMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Υποθέτουμε ότι το dataset έρχεται ως iterator (stream)\n",
        "def reservoir_sample(stream, k=100000):\n",
        "    reservoir = []\n",
        "    for i, item in enumerate(stream):\n",
        "        if i < k:\n",
        "            reservoir.append(item)\n",
        "        else:\n",
        "            j = random.randint(0, i)\n",
        "            if j < k:\n",
        "                reservoir[j] = item\n",
        "    return reservoir\n",
        "\n",
        "# Εφαρμογή σε bookcorpus.csv\n",
        "with open(\"bookcorpus.csv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    next(f)  # skip header\n",
        "    stream = ({\"text\": line.strip()} for line in f)\n",
        "    sampled = reservoir_sample(stream, k=100000)\n",
        "\n",
        "# Αποθήκευση δείγματος\n",
        "df_reservoir = pd.DataFrame(sampled)\n",
        "df_reservoir.to_csv(\"reservoir_sample.csv\", index=False)"
      ],
      "metadata": {
        "id": "h6_2yEwroxb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reservoir = spark.read.csv(\"reservoir_sample.csv\", header=True)\n"
      ],
      "metadata": {
        "id": "D-hjgmO2ozkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, lower, regexp_replace, split, col, length\n",
        "\n",
        "df_tokens_rsv = df_reservoir.select(\n",
        "    explode(\n",
        "        split(\n",
        "            lower(regexp_replace(col(\"text\"), r\"[^a-zA-Z]\", \" \")),\n",
        "            \"\\\\s+\"\n",
        "        )\n",
        "    ).alias(\"word\")\n",
        ").filter(length(col(\"word\")) > 2)\n",
        "\n",
        "word_freq_rsv = df_tokens_rsv.groupBy(\"word\").count().orderBy(col(\"count\").desc())\n",
        "\n",
        "# Πάρε τα top-20 σε pandas\n",
        "top_rsv = word_freq_rsv.limit(20).toPandas()\n",
        "top_rsv"
      ],
      "metadata": {
        "id": "-Y8HJ8F4o1Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmh3\n"
      ],
      "metadata": {
        "id": "xrbE1KfNo3GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mmh3\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class CountMinSketch:\n",
        "    def __init__(self, width=1000, depth=5, seed=42):\n",
        "        self.width = width\n",
        "        self.depth = depth\n",
        "        self.table = np.zeros((depth, width), dtype=int)\n",
        "        self.seeds = [seed + i for i in range(depth)]\n",
        "\n",
        "    def add(self, key):\n",
        "        for i, s in enumerate(self.seeds):\n",
        "            h = mmh3.hash(key, s) % self.width\n",
        "            self.table[i][h] += 1\n",
        "\n",
        "    def estimate(self, key):\n",
        "        return min(\n",
        "            self.table[i][mmh3.hash(key, s) % self.width]\n",
        "            for i, s in enumerate(self.seeds)\n",
        "        )"
      ],
      "metadata": {
        "id": "Nq4eTDd6o41h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Λίστα λέξεων από το sample\n",
        "from collections import Counter\n",
        "words = df_reservoir.toPandas()[\"text\"].str.lower().str.replace(r\"[^a-z ]\", \"\", regex=True).str.split()\n",
        "flat_words = [w for sublist in words for w in sublist if len(w) > 2]\n",
        "\n",
        "true_counts = Counter(flat_words)\n",
        "\n",
        "# Εισαγωγή λέξεων στο Sketch\n",
        "cms = CountMinSketch(width=1000, depth=5)\n",
        "for word in flat_words:\n",
        "    cms.add(word)\n",
        "\n",
        "# Συγκριτικός πίνακας\n",
        "results = []\n",
        "for word, true_val in true_counts.most_common(20):\n",
        "    est_val = cms.estimate(word)\n",
        "    rel_err = 100 * abs(est_val - true_val) / true_val\n",
        "    results.append((word, true_val, est_val, rel_err))\n",
        "\n",
        "import pandas as pd\n",
        "df_sketch = pd.DataFrame(results, columns=[\"word\", \"true\", \"estimated\", \"error_%\"])\n",
        "df_sketch"
      ],
      "metadata": {
        "id": "cd5KPRuno6hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import numpy as np\n",
        "\n",
        "class FMSketch:\n",
        "    def __init__(self, num_hashes=64):\n",
        "        self.num_hashes = num_hashes\n",
        "        self.max_zeroes = np.zeros(num_hashes, dtype=int)\n",
        "\n",
        "    def _hash(self, x, seed):\n",
        "        x = f\"{x}_{seed}\".encode('utf-8')\n",
        "        h = hashlib.sha1(x).hexdigest()\n",
        "        b = bin(int(h, 16))[2:].zfill(160)  # 160-bit string\n",
        "        return b\n",
        "\n",
        "    def add(self, x):\n",
        "        for i in range(self.num_hashes):\n",
        "            b = self._hash(x, i)\n",
        "            self.max_zeroes[i] = max(self.max_zeroes[i], self._rho(b))\n",
        "\n",
        "    def _rho(self, b):\n",
        "        return b.find('1') + 1  # position of first 1\n",
        "\n",
        "    def estimate(self):\n",
        "        return 2 ** (np.median(self.max_zeroes)) / 0.77351"
      ],
      "metadata": {
        "id": "n6dOPi8So9Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flat list of all words από το reservoir\n",
        "words = df_reservoir.toPandas()[\"text\"].str.lower().str.replace(r\"[^a-z ]\", \"\", regex=True).str.split()\n",
        "flat_words = [w for sublist in words for w in sublist if len(w) > 2]\n",
        "\n",
        "# Υπολογισμός ground truth\n",
        "true_unique = len(set(flat_words))\n",
        "\n",
        "# Υπολογισμός με FM\n",
        "fm = FMSketch(num_hashes=64)\n",
        "for w in flat_words:\n",
        "    fm.add(w)\n",
        "\n",
        "estimated_unique = int(fm.estimate())\n",
        "error_percent = abs(estimated_unique - true_unique) / true_unique * 100\n",
        "\n",
        "print(f\"✅ True unique words: {true_unique}\")\n",
        "print(f\"✅ Estimated unique words (FM): {estimated_unique}\")\n",
        "print(f\"🧮 Relative Error: {error_percent:.2f}%\")"
      ],
      "metadata": {
        "id": "4n9FILOso-83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # Fixed import\n",
        "word_lengths = df_reservoir.toPandas()[\"text\"].str.split().map(len)\n",
        "word_lengths.hist(bins=30, figsize=(8, 4))\n",
        "plt.title(\"Histogram of Word Counts per Record\") # Now plt is pyplot\n",
        "plt.xlabel(\"Word Count\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.savefig(\"figures/histogram_wordcount.png\")"
      ],
      "metadata": {
        "id": "SOA6cPFApBMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets # Install using pip\n",
        "import pywt # Then import\n",
        "import numpy as np\n",
        "\n",
        "counts = np.array(word_lengths)\n",
        "coeffs = pywt.wavedec(counts, 'db1', level=3)\n",
        "approx, *details = coeffs\n",
        "!pip install PyWavelets # Install using pip\n",
        "import pywt # Then import\n",
        "import numpy as np\n",
        "\n",
        "counts = np.array(word_lengths)\n",
        "coeffs = pywt.wavedec(counts, 'db1', level=3)\n",
        "approx, *details = coeffs\n",
        "reconstructed = pywt.waverec(coeffs, 'db1')\n",
        "\n",
        "compression_ratio = len(approx) / len(counts)\n",
        "ratio = len(approx) / len(counts)"
      ],
      "metadata": {
        "id": "_Ny0e5xspC56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Λίστα με word counts ανά record\n",
        "word_lengths = df_reservoir.toPandas()[\"text\"].str.split().map(len).to_numpy()\n",
        "\n",
        "# Wavelet decomposition (3 levels)\n",
        "coeffs = pywt.wavedec(word_lengths, wavelet='db1', level=3)\n",
        "approx, *details = coeffs\n",
        "\n",
        "# Reconstruction\n",
        "reconstructed = pywt.waverec(coeffs, wavelet='db1')\n",
        "\n",
        "# Resize to original length\n",
        "reconstructed = reconstructed[:len(word_lengths)]\n",
        "\n",
        "# Compression ratio\n",
        "compression_ratio = len(approx) / len(word_lengths)\n",
        "\n",
        "# Plot original vs reconstructed\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(word_lengths[:500], label=\"Original\")\n",
        "plt.plot(reconstructed[:500], label=\"Reconstructed\", linestyle='--')\n",
        "plt.legend()\n",
        "plt.title(\"Original vs Wavelet-Reconstructed Word Counts\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/wavelet_reconstruction.png\")"
      ],
      "metadata": {
        "id": "kXkDu3mopEfa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}